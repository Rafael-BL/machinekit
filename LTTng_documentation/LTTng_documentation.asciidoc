= *Using LTTng with Machinekit*



== *Introduction*

LTTng is an open source system software package used for tracing the Linux kernel, user applications and libraries. Its usage is relatively simple and the present documentation will show exactly how it can be done in the context of Machinekit. Please note that this is a simple and quick startup guide. For further reference, consult the official LTTng documentation at the following link:

http://lttng.org/docs/


== *Installing LTTng*

Installing LTTng can either be done with packages or built from source. We wont't go into the installation details here because they vary depending on the distributions. Every information on the topic, including desktop distributions, embedded distributions and how to build from source can be found here:

http://lttng.org/docs/#doc-installing-lttng


== *Tracing the Linux Kernel*

In order to trace the linux kernel, one needs to create a tracing session, enable various events, start the tracing and complete the task that has to be traced. Once the task is completed, the tracing has to be stopped and the tracing session destroyed (destroying the session won't destroy the actual trace). It has to be noted that tracing the linux kernel has to be done by a sudo user.

All of those things are done using the lttng tool, which has a Git-like command line structure. The list of available kernel events can be listed by using the following command:

----
lttng list --kernel
----

Enabling a kernel event (in order to get it traced) is done by using the the enable-event command. Here is an example in which we enable the events sched_switch and sched_process_fork:

----
lttng enable-event --kernel  sched_switch,sched_process_fork
----

One can also enable all kernel events at once:

----
lttng enable-event --kernel --all
----

The following code is an example that would result in a trace with all kernel events enabled.

----
sudo lttng create kernelTrace
sudo lttng enable-event --kernel --all
sudo lttng start
//Complete the task that has to be traced
sudo lttng stop
sudo lttng destroy
----

There is also an example of a script to trace the kernel called do-kernel-trace.sh under /scripts/lttng-scripts.
Further references on tracing the linux kernel can be found at the following links:

http://lttng.org/docs/#doc-tracing-the-linux-kernel


== *Tracing a user space application*

In order to trace a user space application, one needs to understand the concept of a tracepoint and of a tracepoint provider. A tracepoint provider is some sort of namespace for tracepoint definitions. A tracepoint could be considered like a printf: it records and outputs various information from any given line (where a tracepoint has been inserted) in some source code.

A tracepoint provider has both a header file and a C file. In the header, we find a few defines needed for the provider. Following those defines, we find the actual tracepoint definitions. Tracepoints are always defined inside the TRACEPOINT_EVENT() macro. For each tracepoint, one must provide a provider name, a tracepoint name, a list of arguments and a list of fields (which are the actual fields of the recorded events). A tracepoint provider header could look like this:

----
#undef TRACEPOINT_PROVIDER
#define TRACEPOINT_PROVIDER hello_world

#undef TRACEPOINT_INCLUDE
#define TRACEPOINT_INCLUDE "./hello-tp.h"

#if !defined(_HELLO_TP_H) || defined(TRACEPOINT_HEADER_MULTI_READ)
#define _HELLO_TP_H

#include <lttng/tracepoint.h>

TRACEPOINT_EVENT(
    hello_world,
    my_first_tracepoint,
    TP_ARGS(
        int, my_integer_arg,
        char*, my_string_arg
    ),
    TP_FIELDS(
        ctf_string(my_string_field, my_string_arg)
        ctf_integer(int, my_integer_field, my_integer_arg)
    )
)

#endif /* _HELLO_TP_H */
#include <lttng/tracepoint-event.h>
----

A list of all the supported TP_FIELDS can be found here:

http://lttng.org/docs/#doc-lttng-ust-ref

The C file matching this tracepoint provider header would be the following:

----
#define TRACEPOINT_CREATE_PROBES
#define TRACEPOINT_DEFINE
#include "hello-tp.h"
----

Finally, the actual tracepoint provider has to be created and linked to the application. There are two common ways of doing that, which are to either statically link the tracepoint provider into the user space application or to compile it as a shared library and to dynamically load it. Further references on building and linking a tracepoint provider can be found here: 

http://lttng.org/docs/#doc-building-tracepoint-providers-and-user-application

However, for the rest of this documentation, we will look more closely at dynamically loading a tracepoint provider that has been compiled as a shared library. Therefore, in order to compile the tracepoint provider, execute the following command:

----
gcc -c -fpic -I. hello-tp.c
----

Then, build it as a shared library like so:

----
gcc -shared -Wl,--no-as-needed -o hello-tp.so -llttng-ust hello-tp.o
----

Now, by dlopening that shared library in the user space application, we can have access to the tracepoint provider and start probing the actual source code.

----
//First line of the main in the application
dlopen("/path-to-shared-library/hello-tp.so", RTLD_LAZY);
----

Now, by including hello-tp.h in a user application (has to be inserted in every source code file where we wish to use the tracepoint() call), we can insert any number of tracepoints using the tracepoint() call. Including hello-tp.h is done like so:

----
#define TRACEPOINT_DEFINE
#define TRACEPOINT_PROBE_DYNAMIC_LINKAGE
#include "/path-to-shared-library/hello-tp.h"
...
tracepoint(hello_world, my_first_tracepoint, 23, "hi there!");
...
----

Finally, in order to trace the actual application, a tracing session has to be created and activated (exactly like when tracing the linux kernel):

----
lttng create user spaceTrace
lttng enable-event --user space hello_world:my_first_tracepoint
lttng start
//Execute the code
lttng stop
----

It has to be noted that listing the user space events is also possible:

----
lttng list --userspace
----

Enabling all user space events at once is also possible :

----
sudo lttng enable-event -u -a
----

There is also, like with the kernel trace, an example of a script that traces the user space of machinekit called do-ust-trace.sh under /scripts/lttng-scripts. Further references on tracing a linux user space application can be found at the following links:

http://lttng.org/docs/#doc-c-application


== *Viewing and analysing a trace*

There are two common ways of viewing and analysing a trace. The first one is by using a command line utility called Babeltrace. The second one, which is the one we are using here, is Trace Compass (available as both an eclipse plugin and a standalone application). Trace Compass has been chosen due to its user-friendliness and clear GUI.

Instructions regarding the installation of Trace Compass can be found here:

http://tracecompass.org/#getting

Once Trace Compass is installed, viewing and analysing a trace becomes fairly simple. More details as to how this is done are found in the following examples. For additional references on how to use Trace Compass make sure to read their user-guide.

http://archive.eclipse.org/tracecompass/doc/org.eclipse.tracecompass.doc.user/User-Guide.html


== *A kernel example*

Let's start with a simple kernel trace that will record how the kernel behaves when launching Machinekit with the Axis GUI. Therefore, we are going to create a tracing session, enable the desired events, accomplish the task (start Machinekit with the Axis GUI), destroy the tracing session and finally look at the trace in Trace Compass. To do so, execute the following commands:

----
#Create the tracing session (trace will be outputed in "./machinekit-kernel")
sudo lttng create kernel -o machinekit-kernel

#Enable kernel events
sudo lttng enable-event -k sched_switch
sudo lttng enable-event -k sched_wakeup
sudo lttng enable-event -k sched_process_fork
sudo lttng enable-event -k sched_process_exec
sudo lttng enable-event -k sched_process_wait
sudo lttng enable-event -k sched_process_exit
sudo lttng enable-event -k --syscall --all

#Start the tracing
sudo lttng start

#Start machinekit ans open the axis GUI
linuxcnc

#Stop the tracing
sudo lttng stop

#Clean the tracing session
sudo lttng destroy -a

#Give proper permission to be able to read the trace in Trace Compass
sudo chmod -R 755 machinekit-kernel
----

Now that the trace has been recorded, we can import it into Trace Compass to have a closer look at it. Once Trace Compass is running, create a new workspace, a new tracing project and finally import the trace. If you are unsure as to how to do so, Trace Compass has very detailed documentation on the topic. It is found at the following link:

http://archive.eclipse.org/tracecompass/doc/org.eclipse.tracecompass.doc.user/Trace-Compass-Main-Features.html#Creating_a_Tracing_Project

Once the trace is imported, open it, and you should now have access to a few different views to analyse your trace. These views include  a control flow that allows you to see the progression of the processes in time, a statistics view, a CPU usage view and a ressources view.

image:./Screenshots/Kernel.png[height=500,link="./Screenshots/Kernel.png"]

More details about viewing and analysing kernel traces:

http://archive.eclipse.org/tracecompass/doc/org.eclipse.tracecompass.doc.user/LTTng-Kernel-Analysis.html#LTTng_Kernel_Analysis


== *A user space example*

In this section, we are going to trace /src/emc/motion/control.c to see precisely how many cycles the function

----
void emcmotController(void *arg, long period)
----

realises when executing the following gcode file.

----
G21        ;metric values
G90        ;absolute positioning
G64 P0.25   ; path mode
G92  A881.340440
F4800
G1 X44.988 Y16.364000 A881.340440 
M2
----

We are also going to look into how much time each of those functions take to complete in each cycle.

----
process_inputs();
do_forward_kins();
process_probe_inputs();
check_for_faults();
set_operating_mode();
handle_jogwheels();
do_homing_sequence();
do_homing();
get_pos_cmds(period);
compute_screw_comp();
output_to_hal();
update_status();
----

The first thing we need to do here is to create, compile and link a tracepoint provider. To do so, we are going to use the following tracepoint provider:

----
//machinekit-tp.c
#define TRACEPOINT_CREATE_PROBES
#include "machinekit_tp.h"

//machinekit-tp.h
#undef TRACEPOINT_PROVIDER
#define TRACEPOINT_PROVIDER machinekit_provider

#if !defined(_MACHINEKIT_TP_H) || defined(TRACEPOINT_HEADER_MULTI_READ)
#define _MACHINEKIT_TP_H

#include <lttng/tracepoint.h>

TRACEPOINT_EVENT(
    machinekit_provider,
    function_timestamp,
    TP_ARGS(
        char*, my_function_name,
        char*, my_function_file
    ),
    TP_FIELDS(
        ctf_string(function_name, my_function_name)
        ctf_string(function_file, my_function_file)
    )
)

TRACEPOINT_EVENT(
    machinekit_provider,
    cycle_counter,
    TP_ARGS(
        char*, my_function_name,
        char*, my_function_file,
        int, my_cycle_count
    ),
    TP_FIELDS(
        ctf_string(function_name, my_function_name)
        ctf_string(function_file, my_function_file)
        ctf_integer(int, cycle_count, my_cycle_count)
    )
)

#endif /* _MACHINEKIT_TP_H */
#undef TRACEPOINT_INCLUDE

#define TRACEPOINT_INCLUDE "./machinekit_tp.h"
#include <lttng/tracepoint-event.h>
----

Then, we simply compile it using the following commands:

----
gcc -c -fpic -I. machinekit_tp.c
gcc -shared -Wl,--no-as-needed -o machinekit_tp.so -llttng-ust machinekit_tp.o
----

Now, by "dlopening" that shared library in the user space application, we can have access to the tracepoint provider and start probing the actual source code.

----
//First line of the main in the application which is under /src/rtapi/rtapi_app.cc
int main(int argc, char **argv)
{
dlopen("/path-to-shared-library/machinekit_tp.so", RTLD_LAZY);
...
}
----

Once that is done, we go into the actual source code we want to trace (/src/emc/motion/control.c). We then insert the header needed to find the tracepoint provider as well as a global variable to count the number of cycles.

----
#define TRACEPOINT_DEFINE
#define TRACEPOINT_PROBE_DYNAMIC_LINKAGE
#include "/path-to-shared-library/machinekit_tp.h"
int cycle_counter = 1;
----

Finally, we insert the actual tracepoints into the source code and we increment the cycle counter at the end of each loop.

----
tracepoint(machinekit_provider, cycle_counter, "before_cycle_counter", "/emc/motion/control.c", cycle_counter);
tracepoint(machinekit_provider, function_timestamp, "before_process_inputs", "/emc/motion/control.c");
process_inputs();
tracepoint(machinekit_provider, function_timestamp, "after_process_inputs", "/emc/motion/control.c");
do_forward_kins();
tracepoint(machinekit_provider, function_timestamp, "after_do_forward_kins", "/emc/motion/control.c");
process_probe_inputs();
tracepoint(machinekit_provider, function_timestamp, "after_process_probe_inputs", "/emc/motion/control.c");
check_for_faults();
tracepoint(machinekit_provider, function_timestamp, "after_check_for_faults", "/emc/motion/control.c");
set_operating_mode();
tracepoint(machinekit_provider, function_timestamp, "after_set_operating_mode", "/emc/motion/control.c");
handle_jogwheels();
tracepoint(machinekit_provider, function_timestamp, "after_handle_jogwheels", "/emc/motion/control.c");
do_homing_sequence();
tracepoint(machinekit_provider, function_timestamp, "after_do_homing_sequence", "/emc/motion/control.c");
do_homing();
tracepoint(machinekit_provider, function_timestamp, "after_do_homing", "/emc/motion/control.c");
get_pos_cmds(period);
tracepoint(machinekit_provider, function_timestamp, "after_get_pos_cmds", "/emc/motion/control.c");
compute_screw_comp();
tracepoint(machinekit_provider, function_timestamp, "after_compute_screw_comp", "/emc/motion/control.c");
output_to_hal();
tracepoint(machinekit_provider, function_timestamp, "after_output_to_hal", "/emc/motion/control.c");
update_status();
tracepoint(machinekit_provider, function_timestamp, "after_update_status", "/emc/motion/control.c");
    /* here ends the core of the controller */
    emcmotStatus->heartbeat++;
    /* set tail to head, to indicate work complete */
    emcmotStatus->tail = emcmotStatus->head;
    /* clear init flag */
    first_pass = 0;
tracepoint(machinekit_provider, cycle_counter, "after_cycle_counter", "/emc/motion/control.c", cycle_counter);
cycle_counter++;
----

Once all that is done, we are ready to recompile the changed files and then trace the application. By executing the following commands, we create a tracing session, we enable the user space events, we start the trace and we execute the task (gcode file).

----
#Create the tracing session (trace will be outputed in "lttng-scripts/machinekit-ust")
sudo lttng create ust -o machinekit-ust

#Enable ust events
sudo lttng enable-event -u -a

#Start the tracing
sudo lttng start

#Start machinekit and execute the gcode file (task to be traced)
linuxcnc

#Stop the tracing
sudo lttng stop

#Clean the tracing session
sudo lttng destroy -a

#Give proper permission to be able to read the trace
sudo chmod -R 755 machinekit-ust
----

Finally, after importing the trace into Trace Compass, we can view and analyse it. Again, we have different views. The main one shows every tracepoint that was recorded with its timestamp and recorded fields. However, viewing many tracepoints in that view and reading every timestamp can be really fastidious. Therefore, in the last section of this documention, we will go over a simple way of writing custom views to better analyse and view user space traces. It should also be noted that, even though tracepoints are light and take very minimal time to execute, having an enormous amount of tracepoints can drastically slow down the execution of an application. For example, the trace we just did has over 500 000 recorded tracepoints, as seen in the statistics
view.

image:./Screenshots/UST.png[height=550,link="./Screenshots/UST.png"]

== *A combined and synchronised kernel and user space example*

It is also possible to record kernel events and user space events simultaneously and to analyse the synchronised recorded traces. This allows you to view what is happening in the kernel when an event occurs in user space and vice-versa. To do so, run the following commands (which are basically a mix of the commands required to trace the kernel and the commands required to trace the user space). We will assume here that the tracepoint provider has already been defined, compiled and that the resulting shared library has been "dlopened" in the main as well as the source code already instrumented.

----
#Create the tracing session (trace will be outputed in "lttng-scripts/machinekit-ust-kernel")
sudo lttng create ust-kernel -o machinekit-ust-kernel

#Enable kernel events
sudo lttng enable-event -k sched_switch
sudo lttng enable-event -k sched_wakeup
sudo lttng enable-event -k sched_process_fork
sudo lttng enable-event -k sched_process_exec
sudo lttng enable-event -k sched_process_wait
sudo lttng enable-event -k sched_process_exit
sudo lttng enable-event -k --syscall --all

#Enable ust events
sudo lttng enable-event -u -a

#Start the tracing
sudo lttng start

#Start machinekit and execute the user space task that needs to be traced (gcode file)
linuxcnc

#Stop the tracing
sudo lttng stop

#Clean the tracing session
sudo lttng destroy -a

#Give proper permission to be able to read the trace
sudo chmod -R 755 machinekit-ust-kernel
----

Once you have the trace opened in Trace Compass, you can open both the recorded kernel and user space events. Double clicking on a user space event will bring out the kernel event that is happening at the same time and vice-versa.

image:./Screenshots/UST-Kernel.png[height=550,link="./Screenshots/UST-Kernel.png"]

More details about viewing and analysing user space traces:

http://archive.eclipse.org/tracecompass/doc/org.eclipse.tracecompass.doc.user/LTTng-UST-Analyses.html#LTTng-UST_Analyses


== *Using an XML analysis to create a custom view*

Finally, as mentionned earlier, viewing user space traces in Trace Compass can be fastidious, especially when analysing multiple timestamps from multiple events. Therefore, this final section will look into defining a custom view to analyse user space traces. That view is created with a simple XML file.

For the purpose of this example, we are going to generate a very simple trace with a few amount of events (only two) in order to have a simple and clear view. We are going to trace the function

----
void emcmotCommandHandler(void *arg, long period) 
----

from /src/emc/motion/command.c when executing the exact same gcode file we used earlier. To do so, we probe that function with a tracepoint at its beginning and one at the end. By doing so, we can not only see how much time the function takes to be executed each time it is called, but we can also see how much time seperates two different executions. Therefore, we are going to create, compile and link the following tracepoint provider.

----
//machinekit2-tp.c
#define TRACEPOINT_CREATE_PROBES
#include "machinekit2_tp.h"

//machinekit2-tp.h
#undef TRACEPOINT_PROVIDER
#define TRACEPOINT_PROVIDER machinekit_provider

#if !defined(_MACHINEKIT_TP2_H) || defined(TRACEPOINT_HEADER_MULTI_READ)
#define _MACHINEKIT_TP_H

#include <lttng/tracepoint.h>
TRACEPOINT_EVENT(
    machinekit_provider,
    command_handle,
    TP_ARGS(
        char*, my_function_file
    ),
    TP_FIELDS(
        ctf_string(function_file, my_function_file)
    )
)

TRACEPOINT_EVENT(
    machinekit_provider,
    after_command_handle,
    TP_ARGS(
        char*, my_function_file
    ),
    TP_FIELDS(
        ctf_string(function_file, my_function_file)
    )
)

#endif /* _MACHINEKIT2_TP_H */
#undef TRACEPOINT_INCLUDE
----

Then, we simply compile it using the following commands:

----
gcc -c -fpic -I. machinekit2_tp.c
gcc -shared -Wl,--no-as-needed -o machinekit2_tp.so -llttng-ust machinekit2_tp.o
----

Then, by "dlopening" that shared library in the user space application, we can have access to the tracepoint provider and start probing the actual source code.

----
//First line of the main in the application
dlopen("/path-to-shared-library/machinekit2_tp.so", RTLD_LAZY);
----

Once that is done, we go into the actual source code we want to trace (/src/emc/motion/command.c). We then insert the header needed to find the tracepoint provider as well as the two tracepoint calls (one at the beginning of the function and of at its end).

----
#define TRACEPOINT_DEFINE
#define TRACEPOINT_PROBE_DYNAMIC_LINKAGE
#include "/path-to-shared-library/machinekit2_tp.h"
...
void emcmotCommandHandler(void *arg, long period)
{
    tracepoint(machinekit_provider, command_handle, "/emc/motion/command.c");
    ...
    tracepoint(machinekit_provider, after_command_handle, "/emc/motion/command.c");
    return;
}
----

Once all that is done, we are ready to recompile and trace the application. By executing the following commands, we create a tracing session, we enable the user space events, we start the trace and we execute the task (gcode file).

----
#Create the tracing session (trace will be outputed in "lttng-scripts/machinekit-ust")
sudo lttng create ust -o machinekit-ust

#Enable ust events
sudo lttng enable-event -u -a

#Start the tracing
sudo lttng start

#Start machinekit and execute the gcode file (task to be traced)
linuxcnc

#Stop the tracing
sudo lttng stop

#Clean the tracing session
sudo lttng destroy -a

#Give proper permission to be able to read the trace
sudo chmod -R 755 machinekit-ust
----

Finally, when we have the trace, we import it into Trace Compass like we did earlier. But this time, we are also going to import an XML analysis that will define and create a view for the traced events. In this context, the XML file will only have two sections. The first one will be a Timegraph View. This section defines a label for the view, the colors that will be assigned to the various events and the display path of each event. The second section, which is the core of the file, is the state provider. It contains, again, a label, some defined values to be assigned to the events and the actual events. A really well written and clear tutorial exists on writing custom XML analysis to define views in Trace Compass. It is found here:

http://archive.eclipse.org/tracecompass/doc/org.eclipse.tracecompass.doc.user/Data-driven-analysis.html

For the purpose of this example however, and to illustrate what it can do, we are going to use the following XML file:

----
<?xml version="1.0" encoding="UTF-8"?>
<tmfxml xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:noNamespaceSchemaLocation="stateprovider1.xsd">

	<!-- The state provider assigns states from events -->
	<stateProvider id="linux.signal.sp1" version="1">
		<head>
			<traceType id="org.eclipse.linuxtools.lttng2.ust.tracetype" />
			<label value="Machinekit UST example" />
		</head>

		<!-- Convenience names for the state values -->
		<definedValue name="COMMAND_HANDLER" value="0" />
		<definedValue name="AFTER_COMMAND_HANDLER" value="1" />

		<!-- Event handlers -->
		<eventHandler eventName="machinekit_provider:command_handle">
			<stateChange>
				<stateAttribute type="constant" value="Thread" />
				<stateAttribute type="eventField" value="function_file" />
				<stateValue type="int" value="$COMMAND_HANDLER" />
			</stateChange>
		</eventHandler>

		<eventHandler eventName="machinekit_provider:after_command_handle">
			<stateChange>
				<stateAttribute type="constant" value="Thread" />
				<stateAttribute type="eventField" value="function_file" />
				<stateValue type="int" value="$AFTER_COMMAND_HANDLER" />
			</stateChange>
		</eventHandler>
	</stateProvider>

	<!-- This is the definition of the time-graph view -->
	<timeGraphView id="linux.signal.timegraph">
		<head>
			<analysis id="linux.signal.sp1" />
			<label value="Machinekit UST View" />
		</head>

		<!-- Colors assigned to the state values -->
		<definedValue name="COMMAND_HANDLER" value="0" color="#FFDD00" />
		<definedValue name="AFTER_COMMAND_HANDLER" value="1" color="#00CC11" />

		<!-- Which attributes to "print" in the view -->
		<entry path="Thread/*">
			<display type="self" />
		</entry>
	</timeGraphView>
</tmfxml>
----

Once imported in Trace Compass, this XML file will create the following view:

image:./Screenshots/XML.png[height=550,link="./Screenshots/XML.png"]

As illustrated in the above picture, the events now have a colored bar that represents how much time they take to be executed. By hovering over one of those bar, we have the details concerning the execution (start time, stop time, timestamp, event name, etc.). Again, by clicking on any event from the other figured view, we are taken directly to the corresponding position in the timegraph view. Using an XML file to define a view can be really advantageous as simply by scrolling through the view, one could see which event takes longer than normal. On a final note, it is worth saying that XML files can also be written to define views for kernel traces.


